<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Individual feed for https://venturebeat.com/category/ai/feed/</title><link>https://venturebeat.com/category/ai/feed/</link><description>Individual feed output.</description><lastBuildDate>Tue, 13 May 2025 12:52:20 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The interoperability breakthrough: How MCP is becoming enterprise AI’s universal language</title><link>https://venturebeat.com/ai/the-interoperability-breakthrough-how-mcp-is-becoming-enterprise-ais-universal-language/</link><image_url>https://venturebeat.com/wp-content/uploads/2025/05/crimedy7_illustration_of_robots_stamping_their_seal_of_approval_d3616e84-f26d-40c0-9e45-4585c582f3a8.png?w=578</image_url><description>Just a few months after it's release, MCP adoption is growing. VentureBeat spoke to some enterprises asking why MCP is winning the standards race.</description><pubDate>Tue, 13 May 2025 14:00:00 GMT</pubDate></item><item><title>Guardian agents: New approach could reduce AI hallucinations to below 1%</title><link>https://venturebeat.com/ai/beyond-detection-why-automatically-correcting-hallucinations-could-transform-enterprise-ai-adoption/</link><image_url>https://venturebeat.com/wp-content/uploads/2025/05/generic-corporate-user-ai-smk.jpg?w=578</image_url><description>There are lots of ways to detect AI hallucination, new guardian agent model promises to correct them.</description><pubDate>Tue, 13 May 2025 14:00:00 GMT</pubDate></item><item><title>Sakana introduces new AI architecture, ‘Continuous Thought Machines’ to make models reason with less guidance — like human brains</title><link>https://venturebeat.com/ai/sakana-introduces-new-ai-architecture-continuous-thought-machines-to-make-models-reason-with-less-guidance-like-human-brains/</link><image_url>https://venturebeat.com/wp-content/uploads/2025/05/cfr0z3n_stark_crisp_neat_pop_art_colorful_flat_illustration_pol_570ae7e2-ddaf-4775-b7da-c0dd0257c8d0.png?w=578</image_url><description>While the CTM shows strong promise, it is still primarily a research architecture and is not yet production-ready out of the box.</description><pubDate>Tue, 13 May 2025 00:08:55 GMT</pubDate></item><item><title>OpenAI just fixed ChatGPT’s most annoying business problem: meet the PDF export that changes everything</title><link>https://venturebeat.com/ai/openai-just-fixed-chatgpts-most-annoying-business-problem-meet-the-pdf-export-that-changes-everything/</link><image_url>https://venturebeat.com/wp-content/uploads/2025/05/nuneybits_Vector_art_of_a_PDF_file_icon_in_pastels_3540832e-2fed-4b22-aee4-d8dd9c16a157.webp?w=578</image_url><description>OpenAI has added a powerful PDF export feature to its Deep Research tool, signaling a major push into enterprise AI and transforming how businesses ge...</description><pubDate>Mon, 12 May 2025 21:43:51 GMT</pubDate></item><item><title>New fully open source vision encoder OpenVision arrives to improve on OpenAI’s Clip, Google’s SigLIP</title><link>https://venturebeat.com/ai/new-fully-open-source-vision-encoder-openvision-arrives-to-improve-on-openais-clip-googles-siglip/</link><image_url>https://venturebeat.com/wp-content/uploads/2025/05/cfr0z3n_stark_crisp_neat_pop_art_yellow_dominant_image_of_a_hum_0c2088ff-9ca4-4b34-8c66-7c8fdb496e14.png?w=578</image_url><description>A vision encoder is a necessary component for allowing many leading LLMs to be able to work with images uploaded by users.</description><pubDate>Mon, 12 May 2025 19:19:20 GMT</pubDate></item></channel></rss>